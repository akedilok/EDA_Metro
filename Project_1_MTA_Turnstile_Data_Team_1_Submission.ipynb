{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: MTA Trunstile Data (Exploratory Data Analysis) \n",
    "## Chicago - Winter 2020 (chi20_ds13): \n",
    "### Team #1 - Ake Paramadilok, Andrew Way, Anthony Ghabour\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objective\n",
    "\n",
    "Use MTA subway (and other) data to help optimize the placement of street teams at entrances to subway stations to identify individuals passionate about technology who might attend a gala at the beginning of the summer.\n",
    "\n",
    "Use python and pandas to perform exploratory data analysis and create visualizations via Matplotlib & Seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Workbook Setup & Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'folium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9fc0d9ee043b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeocoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeocoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNominatim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'folium'"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import geopy.geocoders\n",
    "from geopy.geocoders import Nominatim\n",
    "geopy.geocoders.options.default_user_agent = 'Metis MTA Project 1'\n",
    "geopy.geocoders.options.default_timeout = 15\n",
    "geolocator = Nominatim()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     MTA Data Source: http://web.mta.info/developers/turnstile.html\n",
    "\n",
    "From http://web.mta.info/developers/resources/nyct/turnstile/ts_Field_Description.txt:\n",
    "\n",
    "    Field Description\n",
    "\n",
    "    C/A,UNIT,SCP,STATION,LINENAME,DIVISION,DATE,TIME,DESC,ENTRIES,EXITS\n",
    "\n",
    "    C/A      = Control Area (A002)\n",
    "    UNIT     = Remote Unit for a station (R051)\n",
    "    SCP      = Subunit Channel Position represents an specific address for a device (02-00-00)\n",
    "    STATION  = Represents the station name the device is located at\n",
    "    LINENAME = Represents all train lines that can be boarded at this station\n",
    "               Normally lines are represented by one character.  LINENAME 456NQR repersents train server \n",
    "               for 4, 5, 6, N, Q, and R trains.\n",
    "    DIVISION = Represents the Line originally the station belonged to BMT, IRT, or IND   \n",
    "    DATE     = Represents the date (MM-DD-YY)\n",
    "    TIME     = Represents the time (hh:mm:ss) for a scheduled audit event\n",
    "    DESc     = Represent the \"REGULAR\" scheduled audit event (Normally occurs every 4 hours)\n",
    "               1. Audits may occur more that 4 hours due to planning, or troubleshooting activities. \n",
    "               2. Additionally, there may be a \"RECOVR AUD\" entry: This refers to missed audit that was recovered. \n",
    "    ENTRIES  = The comulative entry register value for a device\n",
    "    EXIST    = The cumulative exit register value for a device\n",
    "\n",
    "\n",
    "Analysis will focus on MTA activity occuring in late Spring (four weeks ending May 25, 2019) in advance of gala event in early Summer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(week_nums):\n",
    "    url = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_{}.txt\"\n",
    "    dfs = []\n",
    "    for week_num in week_nums:\n",
    "        file_url = url.format(week_num)\n",
    "        dfs.append(pd.read_csv(file_url))\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "week_nums = [190504, 190511, 190518, 190525]\n",
    "MTA_df = get_data(week_nums).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Wrangling & Cleanup\n",
    "Let's perform some initial high-level checks. What elements are provided? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df.columns = [column.strip() for column in MTA_df.columns]\n",
    "MTA_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm data reflects the period of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df.DATE.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the applicable data types? Is there any missing information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that date and time are provided as text. Let's combine and convert that information into a single column as a datetime object. Additionally, our analysis will not need to consider time to the nearest minute, so we'll drop minutes and seconds, only keeping time information in terms of hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df[\"DATE_TIME\"] = pd.to_datetime(MTA_df.DATE + \" \" + MTA_df.TIME, format=\"%m/%d/%Y %H:%M:%S\")\n",
    "MTA_df[\"DATE_TIME\"] = MTA_df[\"DATE_TIME\"].transform(lambda x: x.replace(minute = 0, second = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm transformation above worked as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, visually inspect and review a few sample records - first, last, and/or random entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(MTA_df.head())\n",
    "display(MTA_df.tail())\n",
    "display(MTA_df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turnstiles are uniquely identified by a combination of four elements. Let's create a unique identifier to facilitate manipulating later on.<br/> Similarly, sometimes distinct stations (i.e. on different lines) have the same name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df[\"TURNSTILE\"] = (\n",
    "    MTA_df['C/A'] + ' ' +\n",
    "    MTA_df['UNIT'] + ' ' +\n",
    "    MTA_df['SCP'] + ' ' +\n",
    "    MTA_df['STATION'])\n",
    "\n",
    "MTA_df[\"STATION\"] = (\n",
    "    MTA_df['STATION'] + ' ' +\n",
    "    MTA_df['LINENAME'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df.DESC.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Recover audits\" are scarce relative to \"Regular\" audits (less than 0.5% of all records) and may be more likely to involve irregular information, so let's ignore them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df = MTA_df[MTA_df.DESC == \"REGULAR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns we no longer need (much of the information has been incorporated into other columns by now). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df = MTA_df.drop([\"C/A\", \"UNIT\", \"SCP\", \"DESC\", \"DIVISION\", \"LINENAME\"], axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity Check to verify that \"TURNSTILE\", \"DATE_TIME\" combinations are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df = MTA_df.sort_values(\"DATE_TIME\")\n",
    "(MTA_df \n",
    " .sort_values(\"DATE_TIME\")\n",
    " .groupby([\"TURNSTILE\", \"DATE_TIME\"])\n",
    " .ENTRIES.count()\n",
    " .reset_index()\n",
    " .sort_values(\"ENTRIES\", ascending=False)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((MTA_df[\"TURNSTILE\"] == \"R210 R044 00-03-00 BROOKLYN BRIDGE\") & \n",
    "        (MTA_df[\"DATE_TIME\"].dt.date == datetime.datetime(2019, 5, 14).date()))\n",
    "\n",
    "MTA_df[mask].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are multiple entries for the same \"hour\" with small increases in entries and exits. This is easily cleaned up as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df.drop_duplicates(subset = [\"TURNSTILE\", \"DATE_TIME\"], keep=\"last\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((MTA_df[\"TURNSTILE\"] == \"R210 R044 00-03-00 BROOKLYN BRIDGE\") & \n",
    "        (MTA_df[\"DATE_TIME\"].dt.date == datetime.datetime(2019, 5, 14).date()))\n",
    "\n",
    "MTA_df[mask].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm ALL duplicates properly removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(MTA_df \n",
    " .sort_values(\"DATE_TIME\")\n",
    " .groupby([\"TURNSTILE\", \"DATE_TIME\"])\n",
    " .ENTRIES.count()\n",
    " .reset_index()\n",
    " .sort_values(\"ENTRIES\", ascending=False)).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since time data provided not especially granular, let's separate each day into morning and evening commutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df.loc[MTA_df.DATE_TIME.dt.time < datetime.time(13), 'COMMUTE'] = \"Morning\"\n",
    "MTA_df.loc[MTA_df.DATE_TIME.dt.time >= datetime.time(13), 'COMMUTE'] = \"Evening\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(MTA_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since entry and exit information is cumulative, need to shift and take differences in order to get net counts for each day, turnstile, commute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df[[\"PREV_DATE_TIME\", \"PREV_ENTRIES\", \"PREV_EXITS\"]] = (\n",
    "    MTA_df.groupby([\"TURNSTILE\"])[\"DATE_TIME\", \"ENTRIES\", \"EXITS\"]\n",
    "          .transform(lambda grp: grp.shift(1)))\n",
    "MTA_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Street teams won't care if people are coming or going, so we'll combine entries and exits to determine \"total targets\" at each station and limit to a reasonable amount per time period (10,000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(row, max_counter):\n",
    "    counter = row[\"ENTRIES\"] - row[\"PREV_ENTRIES\"]\n",
    "    if counter < 0:\n",
    "        # Maybe counter is reversed?\n",
    "        counter = -counter\n",
    "    if counter > max_counter:\n",
    "        print(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "        counter = min(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "    if counter > max_counter:\n",
    "        # Check it again to make sure we are not giving a counter that's too big\n",
    "        return 0\n",
    "    return counter\n",
    "\n",
    "MTA_df[\"TOTAL_TARGETS\"] = MTA_df.apply(get_counts, axis=1, max_counter=1000000)\n",
    "MTA_df = MTA_df[(MTA_df.TOTAL_TARGETS <= 10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create final, clean data set for exploratory analysis.  Export as csv to handoff to teammate for additional analysis and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTA_EDA_df = MTA_df[[\"STATION\", \"DATE\", \"COMMUTE\", \"TOTAL_TARGETS\"]]\n",
    "MTA_EDA_df.to_csv(r'MTA_EDA.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Analysis\n",
    "### Importing Data and Adding Appropriate Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv into a dataframe object and preview contents\n",
    "\n",
    "filename = 'MTA_EDA.csv'\n",
    "mta_data = pd.read_csv(filename)\n",
    "mta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data characteristics\n",
    "mta_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DATE column to datetime obj\n",
    "mta_data['DATE'] = pd.to_datetime(mta_data['DATE'])\n",
    "\n",
    "# Create WEEKDAY column with string describing day of week\n",
    "mta_data['WEEKDAY'] = mta_data['DATE'].dt.day_name()\n",
    "mta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column with Day Type i.e. weekend or weekday\n",
    "# mta_data now has all columns we need for analysis\n",
    "\n",
    "weekend_days = ['Saturday','Sunday']\n",
    "mta_data['DAY_TYPE'] = mta_data['WEEKDAY'].apply(lambda x: 'weekend' if x in weekend_days else 'weekday') \n",
    "mta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group dataframe by STATION, DATE, COMMUTE, DAY_TYPE and deep copy to mta_grp\n",
    "\n",
    "mta_grp = (mta_data.groupby(['STATION','DATE','COMMUTE','DAY_TYPE'])\n",
    "                  .sum()\n",
    "                  .reset_index()\n",
    "                  .sort_values(\"TOTAL_TARGETS\", ascending=False)\n",
    "                  .copy())\n",
    "mta_grp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize Dataframes for Weekend vs Weekday Rideship Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new grouping of dataframe that will be passed into pivot function for use in scatter plot generation\n",
    "\n",
    "to_pivot = (mta_grp.groupby(['STATION','DAY_TYPE'])\n",
    "                  .mean()\n",
    "                  .reset_index()\n",
    "                  .sort_values(\"TOTAL_TARGETS\", ascending=False))\n",
    "to_pivot.head(15)\n",
    "display(to_pivot.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot Day_Type data into their own columns containing new columns of Weekday and Weekend housing \n",
    "# respective Total_Target values in preparatoin for scatter plot creation\n",
    "\n",
    "scatter_data = to_pivot.pivot('STATION','DAY_TYPE','TOTAL_TARGETS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe for descending weekday volume and save first 10 rows to create a scatter for only top 10 stations.\n",
    "scatter_data_Top10 =(scatter_data.sort_values(\"weekday\", ascending=False)\n",
    "                                .round()\n",
    "                                .head(10))\n",
    "\n",
    "scatter_data_Top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe for descending weekend volume figures just to see it\n",
    "(scatter_data.sort_values(\"weekend\", ascending=False)\n",
    "            .round()\n",
    "            .head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plotting and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot of average daily station traffic on weekends vs. weekdays at ALL stations\n",
    "\n",
    "%matplotlib inline\n",
    "weekend_day_scat = scatter_data.plot.scatter('weekday','weekend');\n",
    "\n",
    "plt.xlim([0,85000]);\n",
    "plt.ylim([0,85000]); \n",
    "#make y-axis scale even with x-axis scalling to emphasize tilt in data towards commuters (weekday rider)\n",
    "plt.title('Average Daily Volume by Station')\n",
    "\n",
    "figure = weekend_day_scat.get_figure()    \n",
    "figure.savefig('Weekday vs Weekend Traffic', dpi=400, bbox_inches='tight',pad_inches=.25,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot of top 10 stations with highest weekday traffic vs their weekend traffic\n",
    "# Chart not useful and was not added to presentation\n",
    "\n",
    "%matplotlib inline\n",
    "weekend_day_scat = scatter_data_Top10.plot.scatter('weekday','weekend');\n",
    "plt.xlim([0,80000]);\n",
    "plt.ylim([0,80000]);\n",
    "plt.title('Average Daily Volume by Station')\n",
    "figure = weekend_day_scat.get_figure()    \n",
    "figure.savefig('Weekday vs Weekend Traffic_top10', dpi=400, bbox_inches='tight',pad_inches=.25,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize Dataframe for Horizontal Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Dataframe by Station and Commute in prep for pivot and save as deep copy after reseting indicies.\n",
    "\n",
    "mta_grp2 = (mta_grp.groupby(['STATION','COMMUTE'])\n",
    "                   .mean()\n",
    "                   .sort_values(\"TOTAL_TARGETS\", ascending=False)\n",
    "                   .reset_index() \n",
    "                   .copy())\n",
    "mta_grp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for PM Ridership Bar Chart for Top 10 stations and pivot data to columns for use in plt\n",
    "\n",
    "mta_grp2_pivot=mta_grp2.pivot('STATION','COMMUTE','TOTAL_TARGETS').reset_index()\n",
    "mta_evening_10 = mta_grp2_pivot.sort_values(\"Evening\", ascending=False)\\\n",
    "    .rename(columns={'Evening':'Average PM Ridership','Morning':'Average AM Ridership'})\n",
    "mta_evening_10.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe for AM Ridership Bar Chart for Top 10 stations\n",
    "\n",
    "mta_morning_10 = (mta_grp2_pivot.sort_values(\"Morning\", ascending=False)\n",
    "                               .reset_index()\n",
    "                               .rename(columns={'Evening':'Average PM Ridership',\\\n",
    "                                                'Morning':'Average AM Ridership'}))\n",
    "mta_morning_10.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP 20 Stations - volume per day\n",
    "\n",
    "mta_grp3 = (mta_grp2.groupby(['STATION'])\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "            .sort_values(\"TOTAL_TARGETS\", ascending=False)\n",
    "            .rename(columns={'TOTAL_TARGETS':'Average Daily Ridership'}))\n",
    "mta_top_10 = mta_grp3.head(10)\n",
    "mta_top_10.to_csv(r'MTA_Top10.csv', index = None, header=True)\n",
    "mta_top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Function to Create Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal bar chart of Top Stations\n",
    "\n",
    "def top_stations(dataframe, num_stations_to_include, col_x_data, col_y_data, title, save_image_name):\n",
    "    \n",
    "    dataframe = dataframe.head(num_stations_to_include)\n",
    "    top_station_all = (sns.barplot(x = col_x_data, \n",
    "                                   y = col_y_data, \n",
    "                                   data = dataframe, \n",
    "                                   orient=\"h\")\n",
    "                                   .set_title(title));\n",
    "    \n",
    "    # store figure to name\n",
    "    figure = top_station_all.get_figure()    \n",
    "    \n",
    "    # save figure and export, bbox_inches \"tight\" to define margins, which were initially cutting off station names\n",
    "    figure.savefig(save_image_name, dpi=400, bbox_inches='tight',pad_inches=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and rename column in order to control bar chart axis name ('Average Daily Ridership')\n",
    "\n",
    "(mta_grp3.reset_index()\n",
    "         .round()\n",
    "         .rename(columns={'TOTAL_TARGETS':'Average Daily Ridership'})\n",
    "         .head(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bar Charts For AM and PM Ridership Using top_stations( ) Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_stations(dataframe = mta_grp3, \n",
    "             num_stations_to_include = 10,\n",
    "             col_x_data = 'Average Daily Ridership', \n",
    "             col_y_data = 'STATION',\n",
    "             title = 'Ave Daily Ridership per Station', \n",
    "             save_image_name = 'Ave_Daily_Vol');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PM Ridership Bar Chart\n",
    "top_stations(dataframe = mta_evening_10, \n",
    "             num_stations_to_include = 10,\n",
    "             col_x_data = 'Average PM Ridership', \n",
    "             col_y_data = 'STATION',\n",
    "             title = 'Ave Evening Ridership per Station', \n",
    "             save_image_name = 'Top_PM_Vol');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AM Ridership Bar Chart\n",
    "top_stations(dataframe = mta_morning_10, \n",
    "             num_stations_to_include = 10,\n",
    "             col_x_data = 'Average AM Ridership', \n",
    "             col_y_data = 'STATION',\n",
    "             title = 'Ave Morning Ridership per Station', \n",
    "             save_image_name = 'Top_AM_Vol');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offices_sqft = pd.read_csv('Location Data - Largest SQFT.csv')\n",
    "offices_pop = pd.read_csv('Location Data - Most Employees.csv')\n",
    "station_data = pd.read_csv('NYC_Transit_Subway_Entrance_And_Exit_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coords(dataframe):\n",
    "    '''\n",
    "    Accepts dataframe of location data with address column,\n",
    "    Adds 2 new float columns to dataframe with latitude and longitude coordinates\n",
    "    for later use in folium map\n",
    "    \n",
    "    Relies on geopy geocode information\n",
    "    Geopy returns 2 cols:\n",
    "        0: str containing descriptive data related to address\n",
    "        1: tuple containing latitude and longitude as floats\n",
    "    \n",
    "    '''\n",
    "    lat,lon = [],[]\n",
    "    for i in range(len(dataframe)):\n",
    "        location = geolocator.geocode(dataframe['Location'][i])\n",
    "        lat.append(location[-1][0])\n",
    "        lon.append(location[-1][1])\n",
    "\n",
    "    dataframe['Latitude'] = lat\n",
    "    dataframe['Longitude'] = lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_coords(offices_sqft)\n",
    "add_coords(offices_pop)\n",
    "#No need to add coordinates to the MTA data, it's already in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data.rename(columns=lambda x: x.strip().replace(' ','_'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,12):\n",
    "    station_data[f'Route{i}']=station_data[f'Route{i}'].astype(str)\n",
    "    station_data[f'Route{i}']=station_data[f'Route{i}'].str.replace('nan','')\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Some MTA lines have numbers for names\n",
    "    and they're in this df as either floats or ints.\n",
    "    This code converts them to strings to concatenate into\n",
    "    an identifying code to prevent overlaps in station names\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data['Station_ID'] =\\\n",
    "station_data['Division']+' '+\\\n",
    "station_data['Line']+' '+\\\n",
    "station_data['Station_Name']+' '+\\\n",
    "station_data['Route1']+\\\n",
    "station_data['Route2']+\\\n",
    "station_data['Route3']+\\\n",
    "station_data['Route4']+\\\n",
    "station_data['Route5']+\\\n",
    "station_data['Route6']+\\\n",
    "station_data['Route7']+\\\n",
    "station_data['Route8']+\\\n",
    "station_data['Route9']+\\\n",
    "station_data['Route10']+\\\n",
    "station_data['Route11']\n",
    "\n",
    "#concatenating individual info into identifying column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_legend = station_data[['Station_Name','Station_ID','Station_Latitude','Station_Longitude']]\n",
    "station_legend.drop_duplicates(inplace=True)\n",
    "station_legend.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#This block creates a legend with just the columns I want,\n",
    "#then removes the repeat entries and resets the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_top_10.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mta_top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next section is pretty ugly and manual.  Given that these datasets have markedly different conventions for name formatting, I'll be poking around to find the correct coordinates and then attach them to the appropriate entry, based on my own domain knowledge of the MTA.  I chose this tactic because the connection between the turnstile 'STATION' entry and station legend 'Station_Name' entry was rather ambiguous. I also knew this  would only be for 10 items, and with the understanding that it isn't scalable much further beyond this quantity.\n",
    "\n",
    "\n",
    "\n",
    "_A Way_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_top_10.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legend_finder(search_query):\n",
    "    return station_legend[station_legend['Station_Name'].str.contains(search_query)]\n",
    "\n",
    "    '''\n",
    "    This function is a shortcut to search for a string in a station name\n",
    "    Input: string, one you expect to be in the station name\n",
    "    Output: df containing entries where input is present in station name\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_finder('Grand Central')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 of our 10 top stations are junctions, stations that serve 2 or more unique lines.  This means that our station legend (and the datasets preceding it) have seperate entries and coordinates for each section of platforms.  For example, in the case of Grand Central, there are 3 entries:\n",
    "\n",
    "Station Name | Description\n",
    ":--|:--\n",
    "IRT Lexington Grand Central-42nd St | the 4/5/6 trains running North/South\n",
    "IRT Flushing Grand Central-42nd St GS4567 | the 7 train running East/West\n",
    "IRT 42nd St Shuttle Grand Central | the S shuttle, a half-length train connecting Grand Central to Times Square\n",
    "\n",
    "Given that our geographical coordinates extend to 6 decimal places, and that differences in geographical coordinates at the 4th decimal place are a maximum of ~30 feet at the equator, these differences are negligible.\n",
    "\n",
    "I'll be using my best judgement to focus on the platform that is closest to ground level and closest to the center of the station, based on renderings from http://www.projectsubwaynyc.com/.\n",
    "\n",
    "_A Way_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_list = []\n",
    "lon_list = [] #we will add coordinates in order to these two lists, then add them to our top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_add(station_string):\n",
    "    lat_list.append(station_legend[station_legend.Station_ID == station_string]\n",
    "                              ['Station_Latitude'])\n",
    "    lon_list.append(station_legend[station_legend.Station_ID == station_string]\n",
    "                              ['Station_Longitude'])\n",
    "    return 'coords_added'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_add('IRT Lexington Grand Central-42nd St GS4567') #4/5/6 platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_top_10.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_finder('34th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_add('BMT Broadway 34th St BDFMNQR') #N/Q/R/W platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_top_10.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_finder('42nd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_add('IND 8 Avenue 42nd St ACENQRS1.02.03.07.0') #'PORT-AUTH' implies 8th avenue line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_top_10.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_finder('34th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_add('IND 8 Avenue 34th St ACE') #Not a junction, no comparisons needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_top_10.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_finder('Union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_add('BMT Canarsie Union Square LNQR456') #L train straddles B'way and Lexington lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_top_10.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_finder('Times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_add('BMT Broadway Times Square-42nd St ACENQRS1.02.03.07.0')\n",
    "# These lines are so close that this one doesn't really matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_top_10.iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_finder('59th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_add('IND 8 Avenue 59th St ABCD1') # 4 of 5 lines at this station are at the aforementioned platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_top_10.iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_finder('Fulton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_add('BMT Nassau Fulton St ACJZ2345.0') #J/Z Nassau line is most central at this location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_top_10.iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_finder('47-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_add('IND 6 Avenue 47-50th Sts Rockefeller Center BDFM') #another non-junction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_top_10.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_finder('Flushing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_add('IRT Flushing Flushing-Main St 7') #non-junction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_top_10['Latitude']=lat_list\n",
    "mta_top_10['Longitude']=lon_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_top_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nycmap = folium.Map(location=[40.73,-73.982155], \n",
    "                    width=1024, \n",
    "                    height=760, \n",
    "                    tiles=\"cartodbpositron\", \n",
    "                    zoom_start=12)\n",
    "\n",
    "for i in range(len(mta_top_10)):\n",
    "    folium.Circle([mta_top_10['Latitude'][i], mta_top_10['Longitude'][i]],\n",
    "                  popup=mta_top_10['STATION'][i],\n",
    "                  radius = 300,\n",
    "                  color = 'crimson',\n",
    "                  fill = True\n",
    "                  ).add_to(nycmap)\n",
    "\n",
    "\n",
    "for i in range(len(offices_pop)):\n",
    "    folium.Circle([offices_pop.iloc[i]['Latitude'], offices_pop.iloc[i]['Longitude']],\n",
    "                  popup=offices_pop.iloc[i]['Company'],\n",
    "                  radius= 10,\n",
    "                  fill=True,\n",
    "                  color = 'blue'\n",
    "                  ).add_to(nycmap)\n",
    "\n",
    "for i in range(len(offices_sqft)):\n",
    "    folium.Circle([offices_sqft.iloc[i]['Latitude'], offices_sqft.iloc[i]['Longitude']],\n",
    "                   popup=offices_sqft.iloc[i]['Company'],\n",
    "                   radius= 10,\n",
    "                   fill=True,\n",
    "                   color = 'blue').add_to(nycmap)\n",
    "\n",
    "nycmap.save('nycmap.html')\n",
    "nycmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
